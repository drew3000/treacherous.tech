---
title: "Stop painting rainbows"
date: 2020-08-08T22:42:32+01:00
tags: [happy to be wrong,]
draft: false
summary: "There's a tendency in talks and really solid books outlining real systemic problems to tack on a sort of 'now, here's the good news' final chapter or post-script. Mostly, these undermine all the points that preceded it."
tldr: "Sometimes there is no upside."

---

I've been reading The Age of Surveillance Capitalism by Shoshana Zuboff. It's a comprehensive, damning and total look at the emergence and rapid growth in the monitoring, collection, analysis and sale of human behaviour, captured in the form of the data exhuast we all emit through doing nearly everything via our devices and various accounts. It was great to recently catch a panel discussion with her on it, but then the *thing* happened again. The moderator in the last few minutes wants to hear the good news. Where is the hope in all this?

You sometimes see these at the end of books as well, particularly those dealing with climate change, corporate/government corruption and the like. But it's fairly common in books and talks on the surveillance states we've got running in the world. When you get to that chapter in the books, you can almost here the publisher asking the author to tack it on, and it's almost always the worst, most trite part of the book. *Here's my axaustive expose on how this horror has emerged unchecked with literally no examples of people doing anything about it... but yippy people power!*

Take face recognition software, a massive game changer in the surveillance market with a whole industry trying to market it combined with AI as the thing that can do nearly anything. It can't, of course, but it might try. And it has various applications that are going to be downright horrendous. Some of them are [happening now](https://thediplomat.com/2020/03/chinas-ubiquitous-facial-recognition-tech-sparks-privacy-backlash/). The EU this year [mulled and then backed off of an outright ban of its use in surveillance tech](https://www.ft.com/content/ff798944-4cc6-11ea-95a0-43d18ec715f5). This should shock absolutely no one, but it will. Policy follows innovation, it rarely leads it.

When the question of "what should we do?" was put to Zuboff, a ban was also her recommendation. It would be wise. It won't happen. People respond viscerally to some tech. [Remember Google Glass](https://www.wired.com/story/google-glass-reasonable-expectation-of-privacy/)? No one wanted it in their face. One of my favorite Seattle dives of the day [made national headlines](https://www.forbes.com/sites/matthickey/2013/11/26/seattle-diner-booting-customers-for-wearing-google-glass/#5074828767e7) for kicking people out for wearing them. It was a moment of surveillance push-back, though mostly symbolic because you could see it in the form of fairly annoying looking headware. But even by then it was a lost cause. Everyone in that same bar has a rectangular device that gathers and shares far more data across multiple networks than any pair of Google specs could do. And we like these ones because they're useful and entertaining and we have the feeling of control over them. Will we ban these as well? C'mon.

Those accurately, precisely, identifying problems shouldn't be on the hook to provide the happy ending. That's group work. It's like painting a rainbow on the side of a building. It's colourful, but it's not a rainbow. It's fake. If you want one of those, you need to organise light to pass through some cascadings water drops with people observing it from the right angle. If you want any change from a current situation, you need to create the conditions in which it naturally occurs.
